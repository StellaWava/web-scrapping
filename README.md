# web-scrapping
In this project,I am exploiting the web crawling frameworks of scrapy, and requests packages to create custom pipelines to extract Airquality data from the EPA [https://www.airnow.gov/maps-and-data/] AirQuality monitoring website. The site host a vast amount of data, but the pipeline utilises the simplest workflow to collect and store data in the csv usable format.
